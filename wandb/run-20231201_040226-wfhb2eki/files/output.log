
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.31s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 1
    mel_loss       : 1.7065340280532837
    fm_loss        : 0.0613555908203125
    gan_loss       : 6.142989158630371
    loss           : 278.2637634277344
    discriminator loss: 7.964862823486328
    grad norm dis  : 8.103721618652344
    grad norm gen  : 10.247786521911621
Train Epoch: 2 [0/1 (0%)] G_Loss: 175.376846 D_Loss: 6.284661
    epoch          : 2
    mel_loss       : 1.6086037158966064
    fm_loss        : 0.06543375551700592
    gan_loss       : 3.8586082458496094
    loss           : 175.37684631347656
    discriminator loss: 6.284661293029785
    grad norm dis  : 6.542550563812256
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.56s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 3 [0/1 (0%)] G_Loss: 72.876625 D_Loss: 4.701199
    epoch          : 3
    mel_loss       : 1.6266590356826782
    fm_loss        : 0.07686280459165573
    gan_loss       : 1.5799163579940796
    loss           : 72.87662506103516
    discriminator loss: 4.701199054718018
    grad norm dis  : 4.8047990798950195
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.75s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.64s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 4
    mel_loss       : 1.5192327499389648
    fm_loss        : 0.08153202384710312
    gan_loss       : 1.0028947591781616
    loss           : 46.81256103515625
    discriminator loss: 4.520504474639893
    grad norm dis  : 8.941225051879883
    grad norm gen  : 9.104198455810547
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.51s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 5
    mel_loss       : 1.5784990787506104
    fm_loss        : 0.09765063226222992
    gan_loss       : 1.863492488861084
    loss           : 85.63096618652344
    discriminator loss: 4.506182670593262
    grad norm dis  : 8.701075553894043
    grad norm gen  : 40.32433319091797
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.36s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 6
    mel_loss       : 1.5118988752365112
    fm_loss        : 0.09631869196891785
    gan_loss       : 2.731597900390625
    loss           : 124.6264419555664
    discriminator loss: 4.074253082275391
    grad norm dis  : 3.4742724895477295
    grad norm gen  : 82.5191421508789
Train Epoch: 7 [0/1 (0%)] G_Loss: 138.832718 D_Loss: 4.060464
    epoch          : 7
    mel_loss       : 1.8001213073730469
    fm_loss        : 0.08874436467885971
    gan_loss       : 3.041224479675293
    loss           : 138.8327178955078
    discriminator loss: 4.060463905334473
    grad norm dis  : 2.808133125305176
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 8 [0/1 (0%)] G_Loss: 127.877777 D_Loss: 4.131669
    epoch          : 8
    mel_loss       : 1.705355167388916
    fm_loss        : 0.08515521883964539
    gan_loss       : 2.800046920776367
    loss           : 127.87777709960938
    discriminator loss: 4.131668567657471
    grad norm dis  : 3.430206060409546
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.78s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 9 [0/1 (0%)] G_Loss: 102.782448 D_Loss: 4.111398
    epoch          : 9
    mel_loss       : 1.7114343643188477
    fm_loss        : 0.0736270323395729
    gan_loss       : 2.2427501678466797
    loss           : 102.7824478149414
    discriminator loss: 4.111398220062256
    grad norm dis  : 2.6475133895874023
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.75s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.74s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 10
    mel_loss       : 2.1656103134155273
    fm_loss        : 0.10736191272735596
    gan_loss       : 1.7696983814239502
    loss           : 82.01676177978516
    discriminator loss: 4.230652809143066
    grad norm dis  : 1.7074964046478271
    grad norm gen  : 248.35337829589844
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.78s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 11
    mel_loss       : 2.264625310897827
    fm_loss        : 0.20951244235038757
    gan_loss       : 1.754652738571167
    loss           : 81.64302062988281
    discriminator loss: 4.641871929168701
    grad norm dis  : 4.74533748626709
    grad norm gen  : 249.21636962890625
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.75s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 12
    mel_loss       : 2.2752819061279297
    fm_loss        : 0.3237537741661072
    gan_loss       : 2.144321918487549
    loss           : 99.41727447509766
    discriminator loss: 4.992550849914551
    grad norm dis  : 5.658888816833496
    grad norm gen  : 228.0774383544922
Train Epoch: 13 [0/1 (0%)] G_Loss: 136.425430 D_Loss: 5.059652
    epoch          : 13
    mel_loss       : 2.7626473903656006
    fm_loss        : 0.4942989945411682
    gan_loss       : 2.948315143585205
    loss           : 136.42543029785156
    discriminator loss: 5.059652328491211
    grad norm dis  : 5.172164440155029
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.59s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 14 [0/1 (0%)] G_Loss: 197.178955 D_Loss: 4.551291
    epoch          : 14
    mel_loss       : 2.4287233352661133
    fm_loss        : 0.9364516735076904
    gan_loss       : 4.286162853240967
    loss           : 197.178955078125
    discriminator loss: 4.551291465759277
    grad norm dis  : 4.394391059875488
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 15 [0/1 (0%)] G_Loss: 270.505402 D_Loss: 3.991498
    epoch          : 15
    mel_loss       : 2.4447035789489746
    fm_loss        : 1.5063999891281128
    gan_loss       : 5.88995361328125
    loss           : 270.5054016113281
    discriminator loss: 3.9914984703063965
    grad norm dis  : 6.305078029632568
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.49s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 16
    mel_loss       : 2.62103009223938
    fm_loss        : 2.232778549194336
    gan_loss       : 7.354774475097656
    loss           : 338.0514221191406
    discriminator loss: 3.285480260848999
    grad norm dis  : 7.649782180786133
    grad norm gen  : 1559.006103515625
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.61s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 17
    mel_loss       : 2.7226431369781494
    fm_loss        : 3.013885974884033
    gan_loss       : 7.468633651733398
    loss           : 344.83892822265625
    discriminator loss: 2.307969808578491
    grad norm dis  : 7.124507427215576
    grad norm gen  : 3178.513427734375
Train Epoch: 18 [0/1 (0%)] G_Loss: 338.401123 D_Loss: 1.822534
    epoch          : 18
    mel_loss       : 2.672440767288208
    fm_loss        : 3.203378438949585
    gan_loss       : 7.318265438079834
    loss           : 338.401123046875
    discriminator loss: 1.8225339651107788
    grad norm dis  : 6.620805263519287
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.74s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.51s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 19
    mel_loss       : 2.3625473976135254
    fm_loss        : 2.3066024780273438
    gan_loss       : 7.688901424407959
    loss           : 352.9762878417969
    discriminator loss: 2.6777291297912598
    grad norm dis  : 17.459575653076172
    grad norm gen  : 5396.7236328125
Train Epoch: 20 [0/1 (0%)] G_Loss: 274.060364 D_Loss: 3.059995
    epoch          : 20
    mel_loss       : 2.15161395072937
    fm_loss        : 1.3761463165283203
    gan_loss       : 5.981255054473877
    loss           : 274.06036376953125
    discriminator loss: 3.05999493598938
    grad norm dis  : 15.428056716918945
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.54s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.38s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 21
    mel_loss       : 1.778069019317627
    fm_loss        : 0.37364107370376587
    gan_loss       : 6.131340026855469
    loss           : 278.4356689453125
    discriminator loss: 3.6140835285186768
    grad norm dis  : 14.603650093078613
    grad norm gen  : 3680.065673828125
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.66s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 22
    mel_loss       : 1.5981608629226685
    fm_loss        : 0.3001396059989929
    gan_loss       : 2.3229293823242188
    loss           : 106.73026275634766
    discriminator loss: 5.75637674331665
    grad norm dis  : 39.51041030883789
    grad norm gen  : 765.0260620117188
Train Epoch: 23 [0/1 (0%)] G_Loss: 91.241119 D_Loss: 6.323595
    epoch          : 23
    mel_loss       : 1.5250340700149536
    fm_loss        : 0.320592999458313
    gan_loss       : 1.9794421195983887
    loss           : 91.24111938476562
    discriminator loss: 6.32359504699707
    grad norm dis  : 35.548423767089844
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.73s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 24
    mel_loss       : 1.6024624109268188
    fm_loss        : 0.25811028480529785
    gan_loss       : 2.2761576175689697
    loss           : 104.5457763671875
    discriminator loss: 5.430869102478027
    grad norm dis  : 23.912567138671875
    grad norm gen  : 707.197998046875
Train Epoch: 25 [0/1 (0%)] G_Loss: 114.928726 D_Loss: 5.033019
    epoch          : 25
    mel_loss       : 1.6770615577697754
    fm_loss        : 0.21482855081558228
    gan_loss       : 2.507155656814575
    loss           : 114.92872619628906
    discriminator loss: 5.033018589019775
    grad norm dis  : 8.061881065368652
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.40s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.38s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 26
    mel_loss       : 1.7688902616500854
    fm_loss        : 0.17835761606693268
    gan_loss       : 2.5126943588256836
    loss           : 115.19684600830078
    discriminator loss: 4.974701404571533
    grad norm dis  : 8.39659595489502
    grad norm gen  : 434.7583312988281
Train Epoch: 27 [0/1 (0%)] G_Loss: 103.874741 D_Loss: 4.835132
    epoch          : 27
    mel_loss       : 1.8271797895431519
    fm_loss        : 0.15631499886512756
    gan_loss       : 2.2607762813568115
    loss           : 103.87474060058594
    discriminator loss: 4.835131645202637
    grad norm dis  : 6.8375468254089355
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.36s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 28 [0/1 (0%)] G_Loss: 91.272858 D_Loss: 4.617855
    epoch          : 28
    mel_loss       : 1.9132041931152344
    fm_loss        : 0.14784453809261322
    gan_loss       : 1.9791991710662842
    loss           : 91.27285766601562
    discriminator loss: 4.617855072021484
    grad norm dis  : 4.416316509246826
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.68s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 29 [0/1 (0%)] G_Loss: 85.954269 D_Loss: 4.431586
    epoch          : 29
    mel_loss       : 1.7686630487442017
    fm_loss        : 0.12139400839805603
    gan_loss       : 1.8653959035873413
    loss           : 85.95426940917969
    discriminator loss: 4.431586265563965
    grad norm dis  : 3.2543721199035645
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.57s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.61s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 30
    mel_loss       : 1.6521973609924316
    fm_loss        : 0.10732991248369217
    gan_loss       : 1.9618115425109863
    loss           : 90.14837646484375
    discriminator loss: 4.333871364593506
    grad norm dis  : 3.249195098876953
    grad norm gen  : 116.89473724365234
Train Epoch: 31 [0/1 (0%)] G_Loss: 97.461014 D_Loss: 4.254968
    epoch          : 31
    mel_loss       : 1.6789108514785767
    fm_loss        : 0.11946297436952591
    gan_loss       : 2.1231815814971924
    loss           : 97.46101379394531
    discriminator loss: 4.254968166351318
    grad norm dis  : 2.545830488204956
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 32 [0/1 (0%)] G_Loss: 101.603867 D_Loss: 4.186232
    epoch          : 32
    mel_loss       : 1.653242826461792
    fm_loss        : 0.12891244888305664
    gan_loss       : 2.21539568901062
    loss           : 101.60386657714844
    discriminator loss: 4.186232089996338
    grad norm dis  : 2.4191482067108154
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.63s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 33 [0/1 (0%)] G_Loss: 101.590118 D_Loss: 4.110072
    epoch          : 33
    mel_loss       : 1.5816049575805664
    fm_loss        : 0.14885492622852325
    gan_loss       : 2.2157955169677734
    loss           : 101.59011840820312
    discriminator loss: 4.110072135925293
    grad norm dis  : 2.3978655338287354
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.85s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 34 [0/1 (0%)] G_Loss: 100.749146 D_Loss: 4.017561
    epoch          : 34
    mel_loss       : 1.6732289791107178
    fm_loss        : 0.1706959307193756
    gan_loss       : 2.1941006183624268
    loss           : 100.7491455078125
    discriminator loss: 4.017561435699463
    grad norm dis  : 2.3855130672454834
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.70s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 35 [0/1 (0%)] G_Loss: 98.493340 D_Loss: 3.905997
    epoch          : 35
    mel_loss       : 1.5180566310882568
    fm_loss        : 0.22411198914051056
    gan_loss       : 2.145045757293701
    loss           : 98.49333953857422
    discriminator loss: 3.905996561050415
    grad norm dis  : 2.3300111293792725
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.72s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 36 [0/1 (0%)] G_Loss: 98.046608 D_Loss: 3.777475
    epoch          : 36
    mel_loss       : 1.6895512342453003
    fm_loss        : 0.3068004250526428
    gan_loss       : 2.1276323795318604
    loss           : 98.0466079711914
    discriminator loss: 3.777475118637085
    grad norm dis  : 2.550541400909424
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.79s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.63s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 37
    mel_loss       : 1.5749566555023193
    fm_loss        : 0.43152332305908203
    gan_loss       : 2.263981342315674
    loss           : 104.3171615600586
    discriminator loss: 3.612241506576538
    grad norm dis  : 3.2439839839935303
    grad norm gen  : 394.39495849609375
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.61s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 38
    mel_loss       : 1.6283739805221558
    fm_loss        : 0.6795101165771484
    gan_loss       : 2.4179975986480713
    loss           : 111.79728698730469
    discriminator loss: 3.4043359756469727
    grad norm dis  : 4.970592975616455
    grad norm gen  : 844.694091796875
Train Epoch: 39 [0/1 (0%)] G_Loss: 134.252197 D_Loss: 3.220511
    epoch          : 39
    mel_loss       : 1.6677207946777344
    fm_loss        : 0.6261043548583984
    gan_loss       : 2.9184951782226562
    loss           : 134.252197265625
    discriminator loss: 3.2205114364624023
    grad norm dis  : 14.840336799621582
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.61s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 40
    mel_loss       : 1.5734846591949463
    fm_loss        : 0.962216317653656
    gan_loss       : 3.290966510772705
    loss           : 151.59140014648438
    discriminator loss: 3.017738103866577
    grad norm dis  : 13.871099472045898
    grad norm gen  : 831.4908447265625
Train Epoch: 41 [0/1 (0%)] G_Loss: 151.347504 D_Loss: 2.788646
    epoch          : 41
    mel_loss       : 1.7492753267288208
    fm_loss        : 1.3560490608215332
    gan_loss       : 3.2641360759735107
    loss           : 151.34750366210938
    discriminator loss: 2.7886459827423096
    grad norm dis  : 7.832059383392334
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.36s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 42 [0/1 (0%)] G_Loss: 208.297150 D_Loss: 2.990076
    epoch          : 42
    mel_loss       : 1.8486993312835693
    fm_loss        : 0.6428759098052979
    gan_loss       : 4.559171199798584
    loss           : 208.29714965820312
    discriminator loss: 2.9900758266448975
    grad norm dis  : 48.76615905761719
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.38s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 43 [0/1 (0%)] G_Loss: 167.178452 D_Loss: 3.375806
    epoch          : 43
    mel_loss       : 1.93310546875
    fm_loss        : 0.8727497458457947
    gan_loss       : 3.6333298683166504
    loss           : 167.17845153808594
    discriminator loss: 3.3758060932159424
    grad norm dis  : 58.935279846191406
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.36s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 44 [0/1 (0%)] G_Loss: 133.330200 D_Loss: 3.623690
    epoch          : 44
    mel_loss       : 1.9562212228775024
    fm_loss        : 0.3372284770011902
    gan_loss       : 2.9044339656829834
    loss           : 133.3302001953125
    discriminator loss: 3.623690128326416
    grad norm dis  : 39.400306701660156
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.38s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 45 [0/1 (0%)] G_Loss: 110.196426 D_Loss: 6.056145
    epoch          : 45
    mel_loss       : 2.3101024627685547
    fm_loss        : 0.5088446736335754
    gan_loss       : 2.3748586177825928
    loss           : 110.19642639160156
    discriminator loss: 6.056144714355469
    grad norm dis  : 38.3168830871582
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.36s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 46 [0/1 (0%)] G_Loss: 110.554626 D_Loss: 7.472754
    epoch          : 46
    mel_loss       : 2.507315158843994
    fm_loss        : 0.603515088558197
    gan_loss       : 2.3742284774780273
    loss           : 110.55462646484375
    discriminator loss: 7.472753524780273
    grad norm dis  : 38.67025375366211
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.35s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 47 [0/1 (0%)] G_Loss: 175.675064 D_Loss: 6.422678
    epoch          : 47
    mel_loss       : 2.805727958679199
    fm_loss        : 0.6779860258102417
    gan_loss       : 3.811408042907715
    loss           : 175.67506408691406
    discriminator loss: 6.422677993774414
    grad norm dis  : 25.25956153869629
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.38s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 48 [0/1 (0%)] G_Loss: 249.491577 D_Loss: 4.825993
    epoch          : 48
    mel_loss       : 2.5705456733703613
    fm_loss        : 1.2772741317749023
    gan_loss       : 5.430366516113281
    loss           : 249.4915771484375
    discriminator loss: 4.825993061065674
    grad norm dis  : 10.071215629577637
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.37s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.36s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 49
    mel_loss       : 2.705678701400757
    fm_loss        : 1.2616405487060547
    gan_loss       : 5.255521774291992
    loss           : 241.72743225097656
    discriminator loss: 4.459445476531982
    grad norm dis  : 10.095047950744629
    grad norm gen  : 3142.0390625
Train Epoch: 50 [0/1 (0%)] G_Loss: 207.743469 D_Loss: 4.492269
    epoch          : 50
    mel_loss       : 2.6433866024017334
    fm_loss        : 0.8121035099029541
    gan_loss       : 4.52168607711792
    loss           : 207.74346923828125
    discriminator loss: 4.4922685623168945
    grad norm dis  : 12.019712448120117
    grad norm gen  : 2070.514892578125
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.37s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 51 [0/1 (0%)] G_Loss: 191.960266 D_Loss: 4.405533
    epoch          : 51
    mel_loss       : 2.6209867000579834
    fm_loss        : 0.49506300687789917
    gan_loss       : 4.185536861419678
    loss           : 191.96026611328125
    discriminator loss: 4.4055328369140625
    grad norm dis  : 8.967720031738281
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.47s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.48s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 52
    mel_loss       : 2.1288228034973145
    fm_loss        : 0.2693576216697693
    gan_loss       : 3.634605884552002
    loss           : 166.2248077392578
    discriminator loss: 4.352569103240967
    grad norm dis  : 6.693953037261963
    grad norm gen  : 1289.7811279296875
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.58s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 53
    mel_loss       : 2.106809377670288
    fm_loss        : 0.13393503427505493
    gan_loss       : 3.078932762145996
    loss           : 140.92665100097656
    discriminator loss: 4.284494876861572
    grad norm dis  : 5.338306903839111
    grad norm gen  : 948.7727661132812
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 54
    mel_loss       : 1.960768699645996
    fm_loss        : 0.0747179239988327
    gan_loss       : 2.6024670600891113
    loss           : 119.22122192382812
    discriminator loss: 4.299332618713379
    grad norm dis  : 5.788174152374268
    grad norm gen  : 479.4732971191406
Train Epoch: 55 [0/1 (0%)] G_Loss: 104.198929 D_Loss: 4.322239
    epoch          : 55
    mel_loss       : 1.890633225440979
    fm_loss        : 0.07793764024972916
    gan_loss       : 2.2700538635253906
    loss           : 104.19892883300781
    discriminator loss: 4.322238922119141
    grad norm dis  : 5.561872482299805
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.69s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 56
    mel_loss       : 1.9069417715072632
    fm_loss        : 0.09869784861803055
    gan_loss       : 1.957509994506836
    loss           : 90.19229125976562
    discriminator loss: 4.364546775817871
    grad norm dis  : 7.100409507751465
    grad norm gen  : 233.37794494628906
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.74s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 57
    mel_loss       : 1.7809946537017822
    fm_loss        : 0.0894465297460556
    gan_loss       : 1.8130755424499512
    loss           : 83.54828643798828
    discriminator loss: 4.278733253479004
    grad norm dis  : 5.582510471343994
    grad norm gen  : 179.88226318359375
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.50s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 58
    mel_loss       : 1.6678714752197266
    fm_loss        : 0.09905818104743958
    gan_loss       : 1.9201395511627197
    loss           : 88.27227020263672
    discriminator loss: 4.196351051330566
    grad norm dis  : 5.200324535369873
    grad norm gen  : 136.6549072265625
Train Epoch: 59 [0/1 (0%)] G_Loss: 94.700729 D_Loss: 4.161708
    epoch          : 59
    mel_loss       : 1.7943512201309204
    fm_loss        : 0.11084073036909103
    gan_loss       : 2.059659957885742
    loss           : 94.70072937011719
    discriminator loss: 4.161707878112793
    grad norm dis  : 3.774383544921875
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.45s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 60 [0/1 (0%)] G_Loss: 96.297989 D_Loss: 4.149345
    epoch          : 60
    mel_loss       : 1.654293417930603
    fm_loss        : 0.11828424036502838
    gan_loss       : 2.0979361534118652
    loss           : 96.29798889160156
    discriminator loss: 4.149345397949219
    grad norm dis  : 4.859644889831543
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.54s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 61 [0/1 (0%)] G_Loss: 98.268883 D_Loss: 4.092432
    epoch          : 61
    mel_loss       : 1.6826611757278442
    fm_loss        : 0.13469980657100677
    gan_loss       : 2.140373706817627
    loss           : 98.26888275146484
    discriminator loss: 4.092431545257568
    grad norm dis  : 4.255101680755615
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.58s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.95s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 62
    mel_loss       : 1.6195313930511475
    fm_loss        : 0.14692051708698273
    gan_loss       : 2.231243133544922
    loss           : 102.31932067871094
    discriminator loss: 4.038973331451416
    grad norm dis  : 4.540861129760742
    grad norm gen  : 141.703125
Train Epoch: 63 [0/1 (0%)] G_Loss: 106.007294 D_Loss: 3.956109
    epoch          : 63
    mel_loss       : 1.762192964553833
    fm_loss        : 0.18093308806419373
    gan_loss       : 2.308516263961792
    loss           : 106.00729370117188
    discriminator loss: 3.956108808517456
    grad norm dis  : 3.741664409637451
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.71s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 64 [0/1 (0%)] G_Loss: 109.210373 D_Loss: 3.883370
    epoch          : 64
    mel_loss       : 1.7433302402496338
    fm_loss        : 0.24676422774791718
    gan_loss       : 2.3771891593933105
    loss           : 109.21037292480469
    discriminator loss: 3.8833701610565186
    grad norm dis  : 4.979078769683838
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.64s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 65 [0/1 (0%)] G_Loss: 117.987000 D_Loss: 3.763692
    epoch          : 65
    mel_loss       : 1.7019706964492798
    fm_loss        : 0.32163697481155396
    gan_loss       : 2.569816827774048
    loss           : 117.98699951171875
    discriminator loss: 3.7636921405792236
    grad norm dis  : 7.558226108551025
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.69s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 66 [0/1 (0%)] G_Loss: 137.060059 D_Loss: 3.574433
    epoch          : 66
    mel_loss       : 1.621181845664978
    fm_loss        : 0.37555378675460815
    gan_loss       : 2.9930617809295654
    loss           : 137.06005859375
    discriminator loss: 3.574432849884033
    grad norm dis  : 16.275781631469727
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 67 [0/1 (0%)] G_Loss: 141.430969 D_Loss: 3.335297
    epoch          : 67
    mel_loss       : 1.6864739656448364
    fm_loss        : 0.4664003252983093
    gan_loss       : 3.0847041606903076
    loss           : 141.43096923828125
    discriminator loss: 3.335297107696533
    grad norm dis  : 7.200892925262451
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.66s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.60s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 68
    mel_loss       : 1.8160557746887207
    fm_loss        : 0.618995189666748
    gan_loss       : 2.9091734886169434
    loss           : 133.96685791015625
    discriminator loss: 3.2721314430236816
    grad norm dis  : 22.747419357299805
    grad norm gen  : 1163.78564453125
Train Epoch: 69 [0/1 (0%)] G_Loss: 130.097778 D_Loss: 3.024766
    epoch          : 69
    mel_loss       : 1.764428973197937
    fm_loss        : 0.7921993732452393
    gan_loss       : 2.816643476486206
    loss           : 130.0977783203125
    discriminator loss: 3.024766445159912
    grad norm dis  : 4.375566005706787
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.71s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.68s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 70
    mel_loss       : 1.7383321523666382
    fm_loss        : 0.9348134994506836
    gan_loss       : 3.348975419998169
    loss           : 154.3118438720703
    discriminator loss: 2.969332218170166
    grad norm dis  : 26.407806396484375
    grad norm gen  : 1416.4443359375
Train Epoch: 71 [0/1 (0%)] G_Loss: 171.560242 D_Loss: 2.805287
    epoch          : 71
    mel_loss       : 1.772599220275879
    fm_loss        : 0.9810304045677185
    gan_loss       : 3.729457378387451
    loss           : 171.56024169921875
    discriminator loss: 2.8052871227264404
    grad norm dis  : 5.456264019012451
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.71s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 72 [0/1 (0%)] G_Loss: 156.017853 D_Loss: 2.875542
    epoch          : 72
    mel_loss       : 1.749569058418274
    fm_loss        : 1.0972803831100464
    gan_loss       : 3.3794162273406982
    loss           : 156.01785278320312
    discriminator loss: 2.875542163848877
    grad norm dis  : 51.06743240356445
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 73 [0/1 (0%)] G_Loss: 211.283722 D_Loss: 2.960942
    epoch          : 73
    mel_loss       : 1.7563025951385498
    fm_loss        : 0.9279846549034119
    gan_loss       : 4.6149210929870605
    loss           : 211.28372192382812
    discriminator loss: 2.960941791534424
    grad norm dis  : 68.9444351196289
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 74 [0/1 (0%)] G_Loss: 155.175690 D_Loss: 3.497007
    epoch          : 74
    mel_loss       : 1.9361671209335327
    fm_loss        : 0.9096384048461914
    gan_loss       : 3.364894151687622
    loss           : 155.17568969726562
    discriminator loss: 3.497007369995117
    grad norm dis  : 46.46924591064453
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.73s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 75 [0/1 (0%)] G_Loss: 176.253204 D_Loss: 5.504523
    epoch          : 75
    mel_loss       : 1.9247883558273315
    fm_loss        : 0.1936604529619217
    gan_loss       : 3.8653576374053955
    loss           : 176.25320434570312
    discriminator loss: 5.504522800445557
    grad norm dis  : 126.2071304321289
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.68s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 76 [0/1 (0%)] G_Loss: 156.138214 D_Loss: 6.906290
    epoch          : 76
    mel_loss       : 2.0118308067321777
    fm_loss        : 0.44712963700294495
    gan_loss       : 3.405158281326294
    loss           : 156.13821411132812
    discriminator loss: 6.906289577484131
    grad norm dis  : 42.73228073120117
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.71s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 77 [0/1 (0%)] G_Loss: 155.645737 D_Loss: 6.742060
    epoch          : 77
    mel_loss       : 2.3566784858703613
    fm_loss        : 0.3359025716781616
    gan_loss       : 3.3914942741394043
    loss           : 155.64573669433594
    discriminator loss: 6.742059707641602
    grad norm dis  : 66.8746109008789
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 78
    mel_loss       : 2.6166675090789795
    fm_loss        : 0.3111879825592041
    gan_loss       : 3.691319704055786
    loss           : 169.3484344482422
    discriminator loss: 5.435232639312744
    grad norm dis  : 31.965055465698242
    grad norm gen  : 1310.5770263671875
Train Epoch: 79 [0/1 (0%)] G_Loss: 158.759491 D_Loss: 4.704531
    epoch          : 79
    mel_loss       : 2.6015589237213135
    fm_loss        : 0.4202606678009033
    gan_loss       : 3.451498031616211
    loss           : 158.75949096679688
    discriminator loss: 4.704530715942383
    grad norm dis  : 14.370528221130371
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.78s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 80 [0/1 (0%)] G_Loss: 165.444183 D_Loss: 4.259586
    epoch          : 80
    mel_loss       : 2.6396524906158447
    fm_loss        : 0.5678309202194214
    gan_loss       : 3.592641592025757
    loss           : 165.44418334960938
    discriminator loss: 4.259586334228516
    grad norm dis  : 16.235492706298828
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:25<00:00, 25.72s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 81 [0/1 (0%)] G_Loss: 187.226395 D_Loss: 3.851898
    epoch          : 81
    mel_loss       : 2.681924343109131
    fm_loss        : 0.659774661064148
    gan_loss       : 4.071664810180664
    loss           : 187.2263946533203
    discriminator loss: 3.851898193359375
    grad norm dis  : 14.611566543579102
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.70s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.63s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 82
    mel_loss       : 2.6583352088928223
    fm_loss        : 0.6408665180206299
    gan_loss       : 4.2270050048828125
    loss           : 194.15528869628906
    discriminator loss: 3.4751577377319336
    grad norm dis  : 20.830257415771484
    grad norm gen  : 2697.75048828125
Train Epoch: 83 [0/1 (0%)] G_Loss: 176.001251 D_Loss: 3.142386
    epoch          : 83
    mel_loss       : 2.539478063583374
    fm_loss        : 0.555171549320221
    gan_loss       : 3.830031633377075
    loss           : 176.00125122070312
    discriminator loss: 3.1423861980438232
    grad norm dis  : 18.12015724182129
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.57s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 84 [0/1 (0%)] G_Loss: 136.956299 D_Loss: 3.037666
    epoch          : 84
    mel_loss       : 2.6891987323760986
    fm_loss        : 0.49112263321876526
    gan_loss       : 2.961885452270508
    loss           : 136.956298828125
    discriminator loss: 3.037666082382202
    grad norm dis  : 11.414018630981445
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.65s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 85 [0/1 (0%)] G_Loss: 162.271072 D_Loss: 3.386660
    epoch          : 85
    mel_loss       : 2.380535364151001
    fm_loss        : 0.3492007851600647
    gan_loss       : 3.5376031398773193
    loss           : 162.2710723876953
    discriminator loss: 3.386660099029541
    grad norm dis  : 18.426557540893555
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.74s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 86 [0/1 (0%)] G_Loss: 119.974380 D_Loss: 4.142907
    epoch          : 86
    mel_loss       : 2.2518460750579834
    fm_loss        : 0.18892619013786316
    gan_loss       : 2.6076595783233643
    loss           : 119.97438049316406
    discriminator loss: 4.14290714263916
    grad norm dis  : 26.994895935058594
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.63s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 87 [0/1 (0%)] G_Loss: 102.316818 D_Loss: 4.065903
    epoch          : 87
    mel_loss       : 2.2096831798553467
    fm_loss        : 0.10775002837181091
    gan_loss       : 2.2198140621185303
    loss           : 102.31681823730469
    discriminator loss: 4.0659027099609375
    grad norm dis  : 10.810602188110352
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.63s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 88 [0/1 (0%)] G_Loss: 118.725121 D_Loss: 4.600493
    epoch          : 88
    mel_loss       : 2.0588488578796387
    fm_loss        : 0.1957738697528839
    gan_loss       : 2.5838828086853027
    loss           : 118.7251205444336
    discriminator loss: 4.60049295425415
    grad norm dis  : 22.952117919921875
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.61s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.78s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 89
    mel_loss       : 1.9236780405044556
    fm_loss        : 0.23968417942523956
    gan_loss       : 2.6405436992645264
    loss           : 121.22750854492188
    discriminator loss: 4.705886363983154
    grad norm dis  : 14.9952974319458
    grad norm gen  : 1405.770751953125
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.75s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 90
    mel_loss       : 2.0015101432800293
    fm_loss        : 0.27652615308761597
    gan_loss       : 2.1814868450164795
    loss           : 100.72147369384766
    discriminator loss: 4.9188385009765625
    grad norm dis  : 19.084714889526367
    grad norm gen  : 729.6175537109375
Train Epoch: 91 [0/1 (0%)] G_Loss: 95.525230 D_Loss: 4.718982
    epoch          : 91
    mel_loss       : 1.985154628753662
    fm_loss        : 0.2891574501991272
    gan_loss       : 2.065816879272461
    loss           : 95.52523040771484
    discriminator loss: 4.718982219696045
    grad norm dis  : 13.804302215576172
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.86s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 92 [0/1 (0%)] G_Loss: 94.857086 D_Loss: 4.525012
    epoch          : 92
    mel_loss       : 2.064528703689575
    fm_loss        : 0.29635483026504517
    gan_loss       : 2.0488853454589844
    loss           : 94.85708618164062
    discriminator loss: 4.525012493133545
    grad norm dis  : 10.779536247253418
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.85s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 93 [0/1 (0%)] G_Loss: 91.951027 D_Loss: 4.328212
    epoch          : 93
    mel_loss       : 2.014539957046509
    fm_loss        : 0.3065006136894226
    gan_loss       : 1.9849662780761719
    loss           : 91.9510269165039
    discriminator loss: 4.328211784362793
    grad norm dis  : 9.81794261932373
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.77s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 94 [0/1 (0%)] G_Loss: 94.769188 D_Loss: 4.161783
    epoch          : 94
    mel_loss       : 2.002570152282715
    fm_loss        : 0.339436411857605
    gan_loss       : 2.0463943481445312
    loss           : 94.7691879272461
    discriminator loss: 4.161783218383789
    grad norm dis  : 9.229452133178711
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.86s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.72s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 95
    mel_loss       : 1.970941185951233
    fm_loss        : 0.369549036026001
    gan_loss       : 2.2085180282592773
    loss           : 102.09334564208984
    discriminator loss: 3.9712698459625244
    grad norm dis  : 7.966061115264893
    grad norm gen  : 244.34426879882812
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.63s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 96
    mel_loss       : 1.952627182006836
    fm_loss        : 0.4142836034297943
    gan_loss       : 2.347276449203491
    loss           : 108.40863800048828
    discriminator loss: 3.7941935062408447
    grad norm dis  : 8.208460807800293
    grad norm gen  : 370.35528564453125
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.78s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 97
    mel_loss       : 2.1094818115234375
    fm_loss        : 0.4686715006828308
    gan_loss       : 2.6189982891082764
    loss           : 120.90174102783203
    discriminator loss: 3.6295242309570312
    grad norm dis  : 7.782215118408203
    grad norm gen  : 512.3713989257812
Train Epoch: 98 [0/1 (0%)] G_Loss: 127.013626 D_Loss: 3.414645
    epoch          : 98
    mel_loss       : 2.2729620933532715
    fm_loss        : 0.529776930809021
    gan_loss       : 2.748469114303589
    loss           : 127.01362609863281
    discriminator loss: 3.414644718170166
    grad norm dis  : 7.009068489074707
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.78s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 99 [0/1 (0%)] G_Loss: 125.051102 D_Loss: 3.208016
    epoch          : 99
    mel_loss       : 2.064303398132324
    fm_loss        : 0.5944151878356934
    gan_loss       : 2.7066214084625244
    loss           : 125.05110168457031
    discriminator loss: 3.2080163955688477
    grad norm dis  : 6.903306007385254
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.80s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.81s/it]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 100
    mel_loss       : 2.1653482913970947
    fm_loss        : 0.6787356734275818
    gan_loss       : 3.0379371643066406
    loss           : 140.22998046875
    discriminator loss: 3.053551435470581
    grad norm dis  : 12.316728591918945
    grad norm gen  : 1067.789306640625
Saving checkpoint: saved/models/deepspeech/1201_040223/checkpoint-epoch100.pth ...
Train Epoch: 101 [0/1 (0%)] G_Loss: 114.489609 D_Loss: 3.010243
    epoch          : 101
    mel_loss       : 2.3038125038146973
    fm_loss        : 0.7500748634338379
    gan_loss       : 2.4596810340881348
    loss           : 114.48960876464844
    discriminator loss: 3.0102429389953613
    grad norm dis  : 32.649749755859375
    grad norm gen  : 1229.042236328125
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 102 [0/1 (0%)] G_Loss: 175.162094 D_Loss: 3.230107
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 102
    mel_loss       : 2.1417934894561768
    fm_loss        : 0.7789086699485779
    gan_loss       : 3.8102774620056152
    loss           : 175.16209411621094
    discriminator loss: 3.230107307434082
    grad norm dis  : 92.36991119384766
    grad norm gen  : 1430.1705322265625
Train Epoch: 103 [0/1 (0%)] G_Loss: 176.134277 D_Loss: 3.339265
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 103
    mel_loss       : 2.0989692211151123
    fm_loss        : 0.8080244064331055
    gan_loss       : 3.8315391540527344
    loss           : 176.13427734375
    discriminator loss: 3.3392648696899414
    grad norm dis  : 57.8790168762207
    grad norm gen  : 956.2256469726562
Train Epoch: 104 [0/1 (0%)] G_Loss: 159.433838 D_Loss: 3.247932
    epoch          : 104
    mel_loss       : 2.0861356258392334
    fm_loss        : 0.8655766844749451
    gan_loss       : 3.4581453800201416
    loss           : 159.433837890625
    discriminator loss: 3.247932195663452
    grad norm dis  : 52.447940826416016
    grad norm gen  : 1134.66357421875
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 105 [0/1 (0%)] G_Loss: 136.280930 D_Loss: 2.603381
    epoch          : 105
    mel_loss       : 2.1291918754577637
    fm_loss        : 0.9482471942901611
    gan_loss       : 2.9390053749084473
    loss           : 136.2809295654297
    discriminator loss: 2.6033811569213867
    grad norm dis  : 6.735524654388428
    grad norm gen  : 962.8013916015625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 106 [0/1 (0%)] G_Loss: 163.542648 D_Loss: 3.208138
    epoch          : 106
    mel_loss       : 2.0788161754608154
    fm_loss        : 1.0032404661178589
    gan_loss       : 3.54349684715271
    loss           : 163.5426483154297
    discriminator loss: 3.2081384658813477
    grad norm dis  : 94.6353530883789
    grad norm gen  : 1547.474365234375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 107 [0/1 (0%)] G_Loss: 184.700027 D_Loss: 2.578781
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 107
    mel_loss       : 2.1450788974761963
    fm_loss        : 0.9936044812202454
    gan_loss       : 4.012616157531738
    loss           : 184.7000274658203
    discriminator loss: 2.5787806510925293
    grad norm dis  : 4.008487701416016
    grad norm gen  : 1461.967041015625
Train Epoch: 108 [0/1 (0%)] G_Loss: 184.066391 D_Loss: 2.840212
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 108
    mel_loss       : 2.16788911819458
    fm_loss        : 1.0342330932617188
    gan_loss       : 3.996222972869873
    loss           : 184.06639099121094
    discriminator loss: 2.840212345123291
    grad norm dis  : 44.34209442138672
    grad norm gen  : 2217.566162109375
Train Epoch: 109 [0/1 (0%)] G_Loss: 172.171097 D_Loss: 2.746581
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 109
    mel_loss       : 1.9584910869598389
    fm_loss        : 1.0678504705429077
    gan_loss       : 3.7350423336029053
    loss           : 172.1710968017578
    discriminator loss: 2.7465810775756836
    grad norm dis  : 35.97024154663086
    grad norm gen  : 3602.59814453125
Train Epoch: 110 [0/1 (0%)] G_Loss: 173.368515 D_Loss: 2.751746
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 110
    mel_loss       : 2.1044464111328125
    fm_loss        : 0.9913362264633179
    gan_loss       : 3.7618091106414795
    loss           : 173.36851501464844
    discriminator loss: 2.7517457008361816
    grad norm dis  : 19.660188674926758
    grad norm gen  : 5583.53857421875
Train Epoch: 111 [0/1 (0%)] G_Loss: 133.403702 D_Loss: 3.250559
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 111
    mel_loss       : 1.8451486825942993
    fm_loss        : 0.5417570471763611
    gan_loss       : 2.8994452953338623
    loss           : 133.40370178222656
    discriminator loss: 3.250558853149414
    grad norm dis  : 42.271427154541016
    grad norm gen  : 4732.02685546875
Train Epoch: 112 [0/1 (0%)] G_Loss: 116.009529 D_Loss: 5.058139
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 112
    mel_loss       : 2.0455660820007324
    fm_loss        : 0.21644227206707
    gan_loss       : 2.5229129791259766
    loss           : 116.00952911376953
    discriminator loss: 5.058139324188232
    grad norm dis  : 121.58882904052734
    grad norm gen  : 6797.59033203125
Train Epoch: 113 [0/1 (0%)] G_Loss: 139.170700 D_Loss: 5.820251
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 113
    mel_loss       : 2.2030887603759766
    fm_loss        : 0.20087704062461853
    gan_loss       : 3.034796714782715
    loss           : 139.1707000732422
    discriminator loss: 5.82025146484375
    grad norm dis  : 51.440208435058594
    grad norm gen  : 2592.17138671875
Train Epoch: 114 [0/1 (0%)] G_Loss: 150.708649 D_Loss: 5.720184
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 114
    mel_loss       : 2.2113196849823
    fm_loss        : 0.5551403164863586
    gan_loss       : 3.2752678394317627
    loss           : 150.70864868164062
    discriminator loss: 5.720183849334717
    grad norm dis  : 51.43989562988281
    grad norm gen  : 1035.783935546875
Train Epoch: 115 [0/1 (0%)] G_Loss: 160.704056 D_Loss: 5.246801
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 115
    mel_loss       : 2.545393943786621
    fm_loss        : 0.7397314310073853
    gan_loss       : 3.481760025024414
    loss           : 160.7040557861328
    discriminator loss: 5.246800899505615
    grad norm dis  : 37.25585174560547
    grad norm gen  : 134.34681701660156
Train Epoch: 116 [0/1 (0%)] G_Loss: 164.640625 D_Loss: 4.356057
    epoch          : 116
    mel_loss       : 2.549272060394287
    fm_loss        : 1.1090043783187866
    gan_loss       : 3.552741050720215
    loss           : 164.640625
    discriminator loss: 4.356057167053223
    grad norm dis  : 28.967988967895508
    grad norm gen  : 712.0792846679688
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 117 [0/1 (0%)] G_Loss: 147.995972 D_Loss: 3.544242
    epoch          : 117
    mel_loss       : 2.488532781600952
    fm_loss        : 1.474074125289917
    gan_loss       : 3.1679842472076416
    loss           : 147.9959716796875
    discriminator loss: 3.5442421436309814
    grad norm dis  : 16.811269760131836
    grad norm gen  : 1280.1885986328125
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 118 [0/1 (0%)] G_Loss: 137.306610 D_Loss: 3.101053
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 118
    mel_loss       : 2.5652072429656982
    fm_loss        : 1.6237170696258545
    gan_loss       : 2.922088146209717
    loss           : 137.30661010742188
    discriminator loss: 3.10105299949646
    grad norm dis  : 11.821001052856445
    grad norm gen  : 1837.5655517578125
Train Epoch: 119 [0/1 (0%)] G_Loss: 153.550430 D_Loss: 2.923177
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 119
    mel_loss       : 2.5212786197662354
    fm_loss        : 1.6113697290420532
    gan_loss       : 3.2845869064331055
    loss           : 153.55043029785156
    discriminator loss: 2.9231765270233154
    grad norm dis  : 21.29248046875
    grad norm gen  : 1833.4908447265625
Train Epoch: 120 [0/1 (0%)] G_Loss: 162.843246 D_Loss: 2.777294
    epoch          : 120
    mel_loss       : 2.4174468517303467
    fm_loss        : 1.4204623699188232
    gan_loss       : 3.5018861293792725
    loss           : 162.84324645996094
    discriminator loss: 2.7772939205169678
    grad norm dis  : 16.481473922729492
    grad norm gen  : 2082.88720703125
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 121 [0/1 (0%)] G_Loss: 164.010941 D_Loss: 2.889591
    epoch          : 121
    mel_loss       : 2.4132156372070312
    fm_loss        : 1.2299742698669434
    gan_loss       : 3.5363948345184326
    loss           : 164.0109405517578
    discriminator loss: 2.8895912170410156
    grad norm dis  : 14.333786964416504
    grad norm gen  : 2181.41455078125
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 122 [0/1 (0%)] G_Loss: 175.184036 D_Loss: 2.976613
    epoch          : 122
    mel_loss       : 2.3325984477996826
    fm_loss        : 1.0665441751480103
    gan_loss       : 3.793741226196289
    loss           : 175.1840362548828
    discriminator loss: 2.9766130447387695
    grad norm dis  : 14.70518684387207
    grad norm gen  : 2330.847412109375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 123 [0/1 (0%)] G_Loss: 152.876190 D_Loss: 3.235228
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 123
    mel_loss       : 2.023841619491577
    fm_loss        : 0.8711643218994141
    gan_loss       : 3.313555955886841
    loss           : 152.87619018554688
    discriminator loss: 3.2352278232574463
    grad norm dis  : 16.537343978881836
    grad norm gen  : 2899.479736328125
Train Epoch: 124 [0/1 (0%)] G_Loss: 131.424484 D_Loss: 3.631142
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 124
    mel_loss       : 1.900206208229065
    fm_loss        : 0.6038528680801392
    gan_loss       : 2.8514792919158936
    loss           : 131.4244842529297
    discriminator loss: 3.6311419010162354
    grad norm dis  : 24.933860778808594
    grad norm gen  : 4130.35595703125
Train Epoch: 125 [0/1 (0%)] G_Loss: 121.686195 D_Loss: 4.112385
    epoch          : 125
    mel_loss       : 1.771637201309204
    fm_loss        : 0.16064877808094025
    gan_loss       : 2.657628059387207
    loss           : 121.68619537353516
    discriminator loss: 4.112384796142578
    grad norm dis  : 16.753509521484375
    grad norm gen  : 4038.62353515625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 126 [0/1 (0%)] G_Loss: 85.043266 D_Loss: 4.567690
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 126
    mel_loss       : 1.6994757652282715
    fm_loss        : 0.3445484936237335
    gan_loss       : 1.8367708921432495
    loss           : 85.04326629638672
    discriminator loss: 4.567690372467041
    grad norm dis  : 32.527679443359375
    grad norm gen  : 1026.115234375
Train Epoch: 127 [0/1 (0%)] G_Loss: 122.789413 D_Loss: 4.955288
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 127
    mel_loss       : 1.6520624160766602
    fm_loss        : 0.19799603521823883
    gan_loss       : 2.6831412315368652
    loss           : 122.78941345214844
    discriminator loss: 4.955288410186768
    grad norm dis  : 67.10523986816406
    grad norm gen  : 152.6559295654297
Train Epoch: 128 [0/1 (0%)] G_Loss: 108.523109 D_Loss: 4.713397
    epoch          : 128
    mel_loss       : 1.7547186613082886
    fm_loss        : 0.21439552307128906
    gan_loss       : 2.3631021976470947
    loss           : 108.52310943603516
    discriminator loss: 4.7133965492248535
    grad norm dis  : 63.09176254272461
    grad norm gen  : 864.7838134765625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 129 [0/1 (0%)] G_Loss: 105.990623 D_Loss: 3.974008
    epoch          : 129
    mel_loss       : 1.6872327327728271
    fm_loss        : 0.4466918706893921
    gan_loss       : 2.2980000972747803
    loss           : 105.9906234741211
    discriminator loss: 3.9740078449249268
    grad norm dis  : 23.613222122192383
    grad norm gen  : 1954.8931884765625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 130 [0/1 (0%)] G_Loss: 118.877594 D_Loss: 3.824101
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 130
    mel_loss       : 1.7684632539749146
    fm_loss        : 0.5522328019142151
    gan_loss       : 2.577881336212158
    loss           : 118.87759399414062
    discriminator loss: 3.824100971221924
    grad norm dis  : 28.553302764892578
    grad norm gen  : 1499.32080078125
Train Epoch: 131 [0/1 (0%)] G_Loss: 132.054520 D_Loss: 3.617530
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 131
    mel_loss       : 1.7860825061798096
    fm_loss        : 0.5818122029304504
    gan_loss       : 2.8689959049224854
    loss           : 132.0545196533203
    discriminator loss: 3.617530107498169
    grad norm dis  : 21.74248504638672
    grad norm gen  : 719.5042724609375
Train Epoch: 132 [0/1 (0%)] G_Loss: 137.146927 D_Loss: 3.459028
    epoch          : 132
    mel_loss       : 1.782250165939331
    fm_loss        : 0.6415430903434753
    gan_loss       : 2.979590892791748
    loss           : 137.1469268798828
    discriminator loss: 3.4590275287628174
    grad norm dis  : 18.540973663330078
    grad norm gen  : 1178.1978759765625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 133 [0/1 (0%)] G_Loss: 126.888908 D_Loss: 3.386801
    epoch          : 133
    mel_loss       : 1.7703481912612915
    fm_loss        : 0.6810935139656067
    gan_loss       : 2.7501416206359863
    loss           : 126.88890838623047
    discriminator loss: 3.386800765991211
    grad norm dis  : 18.014728546142578
    grad norm gen  : 1448.586181640625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 134 [0/1 (0%)] G_Loss: 122.542969 D_Loss: 3.209773
    epoch          : 134
    mel_loss       : 1.682478904724121
    fm_loss        : 0.7736220359802246
    gan_loss       : 2.6514055728912354
    loss           : 122.54296875
    discriminator loss: 3.2097725868225098
    grad norm dis  : 12.177999496459961
    grad norm gen  : 1520.6717529296875
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 135 [0/1 (0%)] G_Loss: 132.339005 D_Loss: 3.079507
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 135
    mel_loss       : 1.7097574472427368
    fm_loss        : 0.9276646971702576
    gan_loss       : 2.861642360687256
    loss           : 132.33900451660156
    discriminator loss: 3.0795071125030518
    grad norm dis  : 18.227081298828125
    grad norm gen  : 2175.965576171875
Train Epoch: 136 [0/1 (0%)] G_Loss: 144.230408 D_Loss: 2.931625
    epoch          : 136
    mel_loss       : 1.6923824548721313
    fm_loss        : 0.9282675385475159
    gan_loss       : 3.1262552738189697
    loss           : 144.23040771484375
    discriminator loss: 2.9316248893737793
    grad norm dis  : 15.891792297363281
    grad norm gen  : 1141.099853515625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 137 [0/1 (0%)] G_Loss: 152.143234 D_Loss: 2.828869
    epoch          : 137
    mel_loss       : 1.6573721170425415
    fm_loss        : 0.9554081559181213
    gan_loss       : 3.3016674518585205
    loss           : 152.1432342529297
    discriminator loss: 2.828868865966797
    grad norm dis  : 19.065082550048828
    grad norm gen  : 2043.4693603515625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 138 [0/1 (0%)] G_Loss: 138.974930 D_Loss: 2.862787
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 138
    mel_loss       : 1.721836805343628
    fm_loss        : 1.0590243339538574
    gan_loss       : 3.0030007362365723
    loss           : 138.9749298095703
    discriminator loss: 2.8627874851226807
    grad norm dis  : 25.392841339111328
    grad norm gen  : 5291.1376953125
Train Epoch: 139 [0/1 (0%)] G_Loss: 171.572769 D_Loss: 2.897957
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 139
    mel_loss       : 1.681637167930603
    fm_loss        : 0.8997986316680908
    gan_loss       : 3.7353675365448
    loss           : 171.57276916503906
    discriminator loss: 2.8979573249816895
    grad norm dis  : 44.162086486816406
    grad norm gen  : 3575.23681640625
Train Epoch: 140 [0/1 (0%)] G_Loss: 161.884521 D_Loss: 3.166677
    epoch          : 140
    mel_loss       : 1.842154622077942
    fm_loss        : 0.4120526611804962
    gan_loss       : 3.5381836891174316
    loss           : 161.884521484375
    discriminator loss: 3.166677474975586
    grad norm dis  : 32.878265380859375
    grad norm gen  : 3452.7666015625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 141 [0/1 (0%)] G_Loss: 143.570770 D_Loss: 3.836915
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 141
    mel_loss       : 1.8927440643310547
    fm_loss        : 0.5331880450248718
    gan_loss       : 3.1247031688690186
    loss           : 143.57077026367188
    discriminator loss: 3.8369152545928955
    grad norm dis  : 22.884193420410156
    grad norm gen  : 8404.3955078125
Train Epoch: 142 [0/1 (0%)] G_Loss: 142.124008 D_Loss: 4.720351
    epoch          : 142
    mel_loss       : 1.9581810235977173
    fm_loss        : 1.2499938011169434
    gan_loss       : 3.0592408180236816
    loss           : 142.12400817871094
    discriminator loss: 4.720351219177246
    grad norm dis  : 60.423954010009766
    grad norm gen  : 2150.948974609375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 143 [0/1 (0%)] G_Loss: 130.297577 D_Loss: 4.333236
    epoch          : 143
    mel_loss       : 1.9811875820159912
    fm_loss        : 1.0701195001602173
    gan_loss       : 2.8039143085479736
    loss           : 130.29757690429688
    discriminator loss: 4.333236217498779
    grad norm dis  : 48.036354064941406
    grad norm gen  : 1265.4925537109375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 144 [0/1 (0%)] G_Loss: 166.717377 D_Loss: 3.726779
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 144
    mel_loss       : 2.1384544372558594
    fm_loss        : 0.49250560998916626
    gan_loss       : 3.635420322418213
    loss           : 166.71737670898438
    discriminator loss: 3.726778745651245
    grad norm dis  : 55.89577102661133
    grad norm gen  : 1595.2257080078125
Train Epoch: 145 [0/1 (0%)] G_Loss: 145.759460 D_Loss: 3.485542
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 145
    mel_loss       : 2.1970741748809814
    fm_loss        : 0.3213917315006256
    gan_loss       : 3.1759912967681885
    loss           : 145.75946044921875
    discriminator loss: 3.4855422973632812
    grad norm dis  : 56.129661560058594
    grad norm gen  : 2127.063232421875
Train Epoch: 146 [0/1 (0%)] G_Loss: 161.950317 D_Loss: 3.454226
    epoch          : 146
    mel_loss       : 2.3962631225585938
    fm_loss        : 0.4266170859336853
    gan_loss       : 3.5266849994659424
    loss           : 161.9503173828125
    discriminator loss: 3.454226493835449
    grad norm dis  : 23.737464904785156
    grad norm gen  : 2504.015625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 147 [0/1 (0%)] G_Loss: 171.283508 D_Loss: 4.208724
    epoch          : 147
    mel_loss       : 2.292415142059326
    fm_loss        : 0.28782811760902405
    gan_loss       : 3.742565155029297
    loss           : 171.28350830078125
    discriminator loss: 4.208724498748779
    grad norm dis  : 39.28834915161133
    grad norm gen  : 2401.39306640625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 148 [0/1 (0%)] G_Loss: 163.011658 D_Loss: 6.382292
    epoch          : 148
    mel_loss       : 2.6371243000030518
    fm_loss        : 0.3730132579803467
    gan_loss       : 3.547300338745117
    loss           : 163.01165771484375
    discriminator loss: 6.3822922706604
    grad norm dis  : 100.86888885498047
    grad norm gen  : 3653.19287109375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 149 [0/1 (0%)] G_Loss: 165.762253 D_Loss: 8.358944
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 149
    mel_loss       : 2.6475939750671387
    fm_loss        : 0.6174823045730591
    gan_loss       : 3.5973267555236816
    loss           : 165.7622528076172
    discriminator loss: 8.358943939208984
    grad norm dis  : 68.22749328613281
    grad norm gen  : 3800.292236328125
Train Epoch: 150 [0/1 (0%)] G_Loss: 208.445145 D_Loss: 7.158524
    epoch          : 150
    mel_loss       : 2.8407187461853027
    fm_loss        : 0.6747959852218628
    gan_loss       : 4.53899621963501
    loss           : 208.4451446533203
    discriminator loss: 7.1585235595703125
    grad norm dis  : 22.019775390625
    grad norm gen  : 1977.2294921875
Saving checkpoint: saved/models/deepspeech/1201_040223/checkpoint-epoch150.pth ...
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 151 [0/1 (0%)] G_Loss: 218.174057 D_Loss: 6.343074
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 151
    mel_loss       : 2.7518460750579834
    fm_loss        : 0.48271504044532776
    gan_loss       : 4.765706539154053
    loss           : 218.17405700683594
    discriminator loss: 6.343073844909668
    grad norm dis  : 21.987003326416016
    grad norm gen  : 2088.516357421875
Train Epoch: 152 [0/1 (0%)] G_Loss: 222.195053 D_Loss: 6.068569
    epoch          : 152
    mel_loss       : 2.969597339630127
    fm_loss        : 0.32867711782455444
    gan_loss       : 4.85706901550293
    loss           : 222.19505310058594
    discriminator loss: 6.068569183349609
    grad norm dis  : 20.24317741394043
    grad norm gen  : 426.3249206542969
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 153 [0/1 (0%)] G_Loss: 225.820358 D_Loss: 5.581495
    epoch          : 153
    mel_loss       : 3.0150442123413086
    fm_loss        : 0.33434340357780457
    gan_loss       : 4.9363694190979
    loss           : 225.8203582763672
    discriminator loss: 5.58149528503418
    grad norm dis  : 18.246070861816406
    grad norm gen  : 1269.384521484375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 154 [0/1 (0%)] G_Loss: 224.899200 D_Loss: 4.848927
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 154
    mel_loss       : 3.024312973022461
    fm_loss        : 0.3721105456352234
    gan_loss       : 4.91401481628418
    loss           : 224.89920043945312
    discriminator loss: 4.848926544189453
    grad norm dis  : 14.593952178955078
    grad norm gen  : 1097.259033203125
Train Epoch: 155 [0/1 (0%)] G_Loss: 240.536682 D_Loss: 4.101552
    epoch          : 155
    mel_loss       : 2.9112277030944824
    fm_loss        : 0.41602852940559387
    gan_loss       : 5.262075424194336
    loss           : 240.53668212890625
    discriminator loss: 4.1015520095825195
    grad norm dis  : 9.12996768951416
    grad norm gen  : 1286.374755859375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 156 [0/1 (0%)] G_Loss: 218.900406 D_Loss: 3.685298
    epoch          : 156
    mel_loss       : 2.983530282974243
    fm_loss        : 0.4617791175842285
    gan_loss       : 4.777629375457764
    loss           : 218.90040588378906
    discriminator loss: 3.685297966003418
    grad norm dis  : 8.251277923583984
    grad norm gen  : 807.2135009765625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 157 [0/1 (0%)] G_Loss: 235.933640 D_Loss: 3.501844
    epoch          : 157
    mel_loss       : 2.974790573120117
    fm_loss        : 0.6661277413368225
    gan_loss       : 5.147257328033447
    loss           : 235.9336395263672
    discriminator loss: 3.5018444061279297
    grad norm dis  : 19.945947647094727
    grad norm gen  : 4152.60693359375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 158 [0/1 (0%)] G_Loss: 219.788651 D_Loss: 2.960649
    epoch          : 158
    mel_loss       : 3.0384230613708496
    fm_loss        : 0.3781106770038605
    gan_loss       : 4.799866676330566
    loss           : 219.7886505126953
    discriminator loss: 2.960649013519287
    grad norm dis  : 10.814019203186035
    grad norm gen  : 887.4808349609375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 159 [0/1 (0%)] G_Loss: 200.685349 D_Loss: 2.735181
    epoch          : 159
    mel_loss       : 2.937683582305908
    fm_loss        : 0.33670586347579956
    gan_loss       : 4.379427909851074
    loss           : 200.6853485107422
    discriminator loss: 2.735180616378784
    grad norm dis  : 7.313607215881348
    grad norm gen  : 825.835693359375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 160 [0/1 (0%)] G_Loss: 184.743652 D_Loss: 2.730805
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 160
    mel_loss       : 2.7650809288024902
    fm_loss        : 0.33396410942077637
    gan_loss       : 4.029125213623047
    loss           : 184.74365234375
    discriminator loss: 2.730804920196533
    grad norm dis  : 9.358027458190918
    grad norm gen  : 977.46435546875
Train Epoch: 161 [0/1 (0%)] G_Loss: 172.353165 D_Loss: 2.737512
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 161
    mel_loss       : 2.602825403213501
    fm_loss        : 0.30388861894607544
    gan_loss       : 3.758723735809326
    loss           : 172.35316467285156
    discriminator loss: 2.73751163482666
    grad norm dis  : 8.883752822875977
    grad norm gen  : 1079.44970703125
Train Epoch: 162 [0/1 (0%)] G_Loss: 184.796356 D_Loss: 2.978680
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 162
    mel_loss       : 2.66288423538208
    fm_loss        : 0.2617192566394806
    gan_loss       : 4.035778522491455
    loss           : 184.79635620117188
    discriminator loss: 2.978679656982422
    grad norm dis  : 7.290946960449219
    grad norm gen  : 1230.09765625
Train Epoch: 163 [0/1 (0%)] G_Loss: 150.575851 D_Loss: 3.509263
    epoch          : 163
    mel_loss       : 2.332106113433838
    fm_loss        : 0.23260805010795593
    gan_loss       : 3.2839674949645996
    loss           : 150.5758514404297
    discriminator loss: 3.509262800216675
    grad norm dis  : 8.498727798461914
    grad norm gen  : 618.82666015625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 164 [0/1 (0%)] G_Loss: 152.748245 D_Loss: 3.937856
    epoch          : 164
    mel_loss       : 2.1724376678466797
    fm_loss        : 0.19526100158691406
    gan_loss       : 3.3374507427215576
    loss           : 152.7482452392578
    discriminator loss: 3.937856435775757
    grad norm dis  : 16.942840576171875
    grad norm gen  : 619.1590576171875
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 165 [0/1 (0%)] G_Loss: 94.241158 D_Loss: 4.248474
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 165
    mel_loss       : 2.0665833950042725
    fm_loss        : 0.18190796673297882
    gan_loss       : 2.040239095687866
    loss           : 94.24115753173828
    discriminator loss: 4.248473644256592
    grad norm dis  : 32.78716278076172
    grad norm gen  : 344.6603698730469
Train Epoch: 166 [0/1 (0%)] G_Loss: 107.270966 D_Loss: 4.638391
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 166
    mel_loss       : 1.857202172279358
    fm_loss        : 0.22241978347301483
    gan_loss       : 2.3326427936553955
    loss           : 107.27096557617188
    discriminator loss: 4.638391017913818
    grad norm dis  : 31.164295196533203
    grad norm gen  : 251.4561767578125
Train Epoch: 167 [0/1 (0%)] G_Loss: 106.435158 D_Loss: 4.337701
    epoch          : 167
    mel_loss       : 1.8482024669647217
    fm_loss        : 0.22868500649929047
    gan_loss       : 2.313990831375122
    loss           : 106.4351577758789
    discriminator loss: 4.337700843811035
    grad norm dis  : 10.780360221862793
    grad norm gen  : 193.9391326904297
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 168 [0/1 (0%)] G_Loss: 115.949821 D_Loss: 4.905667
    epoch          : 168
    mel_loss       : 1.8705856800079346
    fm_loss        : 0.2887150049209595
    gan_loss       : 2.5222623348236084
    loss           : 115.94982147216797
    discriminator loss: 4.905667304992676
    grad norm dis  : 29.897666931152344
    grad norm gen  : 237.7304229736328
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 169 [0/1 (0%)] G_Loss: 110.375168 D_Loss: 4.473295
    epoch          : 169
    mel_loss       : 1.7137082815170288
    fm_loss        : 0.3253086507320404
    gan_loss       : 2.400240898132324
    loss           : 110.37516784667969
    discriminator loss: 4.473295211791992
    grad norm dis  : 11.97819709777832
    grad norm gen  : 303.1153869628906
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 170 [0/1 (0%)] G_Loss: 111.749008 D_Loss: 4.464750
    epoch          : 170
    mel_loss       : 1.679027795791626
    fm_loss        : 0.340588241815567
    gan_loss       : 2.4308621883392334
    loss           : 111.74900817871094
    discriminator loss: 4.464750289916992
    grad norm dis  : 11.916592597961426
    grad norm gen  : 114.5120849609375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 171 [0/1 (0%)] G_Loss: 105.818199 D_Loss: 4.356012
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 171
    mel_loss       : 1.713645100593567
    fm_loss        : 0.38601985573768616
    gan_loss       : 2.2962779998779297
    loss           : 105.81819915771484
    discriminator loss: 4.356012344360352
    grad norm dis  : 12.506875991821289
    grad norm gen  : 153.3668212890625
Train Epoch: 172 [0/1 (0%)] G_Loss: 94.822426 D_Loss: 4.172725
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 172
    mel_loss       : 1.8124237060546875
    fm_loss        : 0.42378726601600647
    gan_loss       : 2.0480539798736572
    loss           : 94.82242584228516
    discriminator loss: 4.172725200653076
    grad norm dis  : 8.505891799926758
    grad norm gen  : 379.1193542480469
Train Epoch: 173 [0/1 (0%)] G_Loss: 119.082253 D_Loss: 4.257056
    epoch          : 173
    mel_loss       : 1.7809032201766968
    fm_loss        : 0.5034564137458801
    gan_loss       : 2.5843207836151123
    loss           : 119.0822525024414
    discriminator loss: 4.25705623626709
    grad norm dis  : 58.83843231201172
    grad norm gen  : 48.044151306152344
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 174 [0/1 (0%)] G_Loss: 121.382553 D_Loss: 4.068195
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 174
    mel_loss       : 1.6458603143692017
    fm_loss        : 0.3267071843147278
    gan_loss       : 2.6462950706481934
    loss           : 121.38255310058594
    discriminator loss: 4.06819486618042
    grad norm dis  : 14.221878051757812
    grad norm gen  : 32.805702209472656
Train Epoch: 175 [0/1 (0%)] G_Loss: 115.024948 D_Loss: 4.031561
    epoch          : 175
    mel_loss       : 1.74007248878479
    fm_loss        : 0.44932276010513306
    gan_loss       : 2.497471809387207
    loss           : 115.02494812011719
    discriminator loss: 4.031561374664307
    grad norm dis  : 12.291796684265137
    grad norm gen  : 22.243776321411133
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 176 [0/1 (0%)] G_Loss: 104.520073 D_Loss: 3.958727
    epoch          : 176
    mel_loss       : 1.6629910469055176
    fm_loss        : 0.4546855688095093
    gan_loss       : 2.2655045986175537
    loss           : 104.52007293701172
    discriminator loss: 3.9587268829345703
    grad norm dis  : 9.668962478637695
    grad norm gen  : 16.432130813598633
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 177 [0/1 (0%)] G_Loss: 96.943329 D_Loss: 3.885793
    epoch          : 177
    mel_loss       : 1.73198401927948
    fm_loss        : 0.4767172634601593
    gan_loss       : 2.0946202278137207
    loss           : 96.94332885742188
    discriminator loss: 3.885793447494507
    grad norm dis  : 7.051539897918701
    grad norm gen  : 17.784610748291016
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 178 [0/1 (0%)] G_Loss: 95.969383 D_Loss: 3.848352
    epoch          : 178
    mel_loss       : 1.7672314643859863
    fm_loss        : 0.5928714275360107
    gan_loss       : 2.0670313835144043
    loss           : 95.9693832397461
    discriminator loss: 3.8483521938323975
    grad norm dis  : 3.7913007736206055
    grad norm gen  : 20.1001033782959
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 179 [0/1 (0%)] G_Loss: 97.419289 D_Loss: 3.847851
    epoch          : 179
    mel_loss       : 1.7849594354629517
    fm_loss        : 0.4411071836948395
    gan_loss       : 2.105602502822876
    loss           : 97.4192886352539
    discriminator loss: 3.847851037979126
    grad norm dis  : 4.565680027008057
    grad norm gen  : 20.735502243041992
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 180 [0/1 (0%)] G_Loss: 104.321495 D_Loss: 4.076114
    epoch          : 180
    mel_loss       : 1.7439128160476685
    fm_loss        : 0.5720668435096741
    gan_loss       : 2.2540767192840576
    loss           : 104.32149505615234
    discriminator loss: 4.076114177703857
    grad norm dis  : 13.896257400512695
    grad norm gen  : 25.865558624267578
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 181 [0/1 (0%)] G_Loss: 110.385155 D_Loss: 3.730580
    epoch          : 181
    mel_loss       : 1.6237337589263916
    fm_loss        : 0.5523331761360168
    gan_loss       : 2.3923723697662354
    loss           : 110.3851547241211
    discriminator loss: 3.7305798530578613
    grad norm dis  : 3.7049190998077393
    grad norm gen  : 59.064613342285156
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 182 [0/1 (0%)] G_Loss: 111.405861 D_Loss: 3.744638
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 182
    mel_loss       : 1.7341991662979126
    fm_loss        : 0.3704776465892792
    gan_loss       : 2.420682430267334
    loss           : 111.4058609008789
    discriminator loss: 3.7446377277374268
    grad norm dis  : 8.681557655334473
    grad norm gen  : 60.87180709838867
Train Epoch: 183 [0/1 (0%)] G_Loss: 110.089073 D_Loss: 3.777942
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 183
    mel_loss       : 1.825984001159668
    fm_loss        : 0.3664990961551666
    gan_loss       : 2.3895576000213623
    loss           : 110.08907318115234
    discriminator loss: 3.777941942214966
    grad norm dis  : 8.458312034606934
    grad norm gen  : 31.19037437438965
Train Epoch: 184 [0/1 (0%)] G_Loss: 108.156265 D_Loss: 3.649760
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 184
    mel_loss       : 1.5755414962768555
    fm_loss        : 0.4708385765552521
    gan_loss       : 2.347534418106079
    loss           : 108.15626525878906
    discriminator loss: 3.6497597694396973
    grad norm dis  : 8.032526969909668
    grad norm gen  : 46.67867660522461
Train Epoch: 185 [0/1 (0%)] G_Loss: 103.671349 D_Loss: 3.673535
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 185
    mel_loss       : 1.8346821069717407
    fm_loss        : 0.4344339072704315
    gan_loss       : 2.2437288761138916
    loss           : 103.67134857177734
    discriminator loss: 3.673534870147705
    grad norm dis  : 6.31016206741333
    grad norm gen  : 56.03046798706055
Train Epoch: 186 [0/1 (0%)] G_Loss: 116.182114 D_Loss: 3.541269
    epoch          : 186
    mel_loss       : 1.6926639080047607
    fm_loss        : 0.6806142330169678
    gan_loss       : 2.513960361480713
    loss           : 116.18211364746094
    discriminator loss: 3.541268825531006
    grad norm dis  : 10.919215202331543
    grad norm gen  : 62.236236572265625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 187 [0/1 (0%)] G_Loss: 108.310539 D_Loss: 3.601074
    epoch          : 187
    mel_loss       : 1.700387716293335
    fm_loss        : 0.5472713112831116
    gan_loss       : 2.3447914123535156
    loss           : 108.31053924560547
    discriminator loss: 3.601073980331421
    grad norm dis  : 9.93217658996582
    grad norm gen  : 64.236328125
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 188 [0/1 (0%)] G_Loss: 128.076538 D_Loss: 3.391366
    epoch          : 188
    mel_loss       : 1.705474853515625
    fm_loss        : 0.8326122164726257
    gan_loss       : 2.771240711212158
    loss           : 128.0765380859375
    discriminator loss: 3.3913660049438477
    grad norm dis  : 11.086457252502441
    grad norm gen  : 50.35221481323242
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 189 [0/1 (0%)] G_Loss: 132.534073 D_Loss: 3.283805
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 189
    mel_loss       : 1.6257892847061157
    fm_loss        : 0.8291738629341125
    gan_loss       : 2.872220754623413
    loss           : 132.53407287597656
    discriminator loss: 3.2838053703308105
    grad norm dis  : 6.109294891357422
    grad norm gen  : 42.147640228271484
Train Epoch: 190 [0/1 (0%)] G_Loss: 125.287048 D_Loss: 3.539038
    epoch          : 190
    mel_loss       : 1.8538572788238525
    fm_loss        : 0.6608664989471436
    gan_loss       : 2.713587999343872
    loss           : 125.28704833984375
    discriminator loss: 3.5390379428863525
    grad norm dis  : 11.312688827514648
    grad norm gen  : 140.194091796875
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 191 [0/1 (0%)] G_Loss: 136.423248 D_Loss: 3.318027
    epoch          : 191
    mel_loss       : 1.8288346529006958
    fm_loss        : 0.8278271555900574
    gan_loss       : 2.9541947841644287
    loss           : 136.42324829101562
    discriminator loss: 3.318026542663574
    grad norm dis  : 10.727309226989746
    grad norm gen  : 230.74058532714844
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 192 [0/1 (0%)] G_Loss: 139.146194 D_Loss: 3.261404
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 192
    mel_loss       : 1.8248189687728882
    fm_loss        : 0.7629162073135376
    gan_loss       : 3.017678737640381
    loss           : 139.1461944580078
    discriminator loss: 3.261404275894165
    grad norm dis  : 8.152585983276367
    grad norm gen  : 269.0554504394531
Train Epoch: 193 [0/1 (0%)] G_Loss: 124.191055 D_Loss: 3.437381
    epoch          : 193
    mel_loss       : 1.9332921504974365
    fm_loss        : 0.6888917088508606
    gan_loss       : 2.6862218379974365
    loss           : 124.19105529785156
    discriminator loss: 3.43738055229187
    grad norm dis  : 10.285904884338379
    grad norm gen  : 162.2581329345703
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 194 [0/1 (0%)] G_Loss: 146.268234 D_Loss: 3.364111
    epoch          : 194
    mel_loss       : 1.859361171722412
    fm_loss        : 0.6461144685745239
    gan_loss       : 3.1803698539733887
    loss           : 146.2682342529297
    discriminator loss: 3.3641107082366943
    grad norm dis  : 13.789188385009766
    grad norm gen  : 172.18577575683594
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 195 [0/1 (0%)] G_Loss: 144.144501 D_Loss: 3.488476
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 195
    mel_loss       : 1.8292127847671509
    fm_loss        : 0.7828900218009949
    gan_loss       : 3.1277670860290527
    loss           : 144.14450073242188
    discriminator loss: 3.4884755611419678
    grad norm dis  : 10.162396430969238
    grad norm gen  : 172.63668823242188
Train Epoch: 196 [0/1 (0%)] G_Loss: 123.874603 D_Loss: 3.405106
    epoch          : 196
    mel_loss       : 1.8705624341964722
    fm_loss        : 0.6622663736343384
    gan_loss       : 2.681766986846924
    loss           : 123.87460327148438
    discriminator loss: 3.4051060676574707
    grad norm dis  : 8.236529350280762
    grad norm gen  : 163.7328338623047
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 197 [0/1 (0%)] G_Loss: 143.562790 D_Loss: 3.332225
    epoch          : 197
    mel_loss       : 1.9166343212127686
    fm_loss        : 0.690869152545929
    gan_loss       : 3.1169872283935547
    loss           : 143.5627899169922
    discriminator loss: 3.3322248458862305
    grad norm dis  : 12.8026762008667
    grad norm gen  : 232.36965942382812
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 198 [0/1 (0%)] G_Loss: 132.158325 D_Loss: 3.477716
    epoch          : 198
    mel_loss       : 2.0949912071228027
    fm_loss        : 0.6171537041664124
    gan_loss       : 2.8628673553466797
    loss           : 132.1583251953125
    discriminator loss: 3.4777164459228516
    grad norm dis  : 14.325838088989258
    grad norm gen  : 226.9329833984375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 199 [0/1 (0%)] G_Loss: 141.014404 D_Loss: 3.462938
    epoch          : 199
    mel_loss       : 2.011096954345703
    fm_loss        : 0.6069734692573547
    gan_loss       : 3.061985969543457
    loss           : 141.014404296875
    discriminator loss: 3.4629383087158203
    grad norm dis  : 17.87127685546875
    grad norm gen  : 396.078857421875
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 200 [0/1 (0%)] G_Loss: 133.426453 D_Loss: 3.648755
    epoch          : 200
    mel_loss       : 2.13004994392395
    fm_loss        : 0.6008532047271729
    gan_loss       : 2.890993356704712
    loss           : 133.42645263671875
    discriminator loss: 3.6487550735473633
    grad norm dis  : 15.438305854797363
    grad norm gen  : 618.8745727539062
Saving checkpoint: saved/models/deepspeech/1201_040223/checkpoint-epoch200.pth ...
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 201 [0/1 (0%)] G_Loss: 121.580566 D_Loss: 3.797859
    epoch          : 201
    mel_loss       : 2.2241601943969727
    fm_loss        : 0.5521752238273621
    gan_loss       : 2.6278233528137207
    loss           : 121.58056640625
    discriminator loss: 3.7978594303131104
    grad norm dis  : 16.13966941833496
    grad norm gen  : 1001.7203369140625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 202 [0/1 (0%)] G_Loss: 140.635620 D_Loss: 4.098848
    epoch          : 202
    mel_loss       : 2.4025533199310303
    fm_loss        : 0.5148036479949951
    gan_loss       : 3.0489656925201416
    loss           : 140.6356201171875
    discriminator loss: 4.09884786605835
    grad norm dis  : 26.891752243041992
    grad norm gen  : 1449.8109130859375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 203 [0/1 (0%)] G_Loss: 143.986465 D_Loss: 3.871402
    epoch          : 203
    mel_loss       : 2.251156806945801
    fm_loss        : 0.558464527130127
    gan_loss       : 3.1248528957366943
    loss           : 143.98646545410156
    discriminator loss: 3.8714022636413574
    grad norm dis  : 11.601065635681152
    grad norm gen  : 1880.2086181640625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 204 [0/1 (0%)] G_Loss: 125.020035 D_Loss: 4.264870
    epoch          : 204
    mel_loss       : 2.45780348777771
    fm_loss        : 0.45413950085639954
    gan_loss       : 2.703421115875244
    loss           : 125.02003479003906
    discriminator loss: 4.264869689941406
    grad norm dis  : 22.140974044799805
    grad norm gen  : 1544.659912109375
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 205 [0/1 (0%)] G_Loss: 126.387779 D_Loss: 4.061964
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 205
    mel_loss       : 2.615316390991211
    fm_loss        : 0.4239199459552765
    gan_loss       : 2.7316582202911377
    loss           : 126.38777923583984
    discriminator loss: 4.06196403503418
    grad norm dis  : 13.408953666687012
    grad norm gen  : 672.361083984375
Train Epoch: 206 [0/1 (0%)] G_Loss: 157.611481 D_Loss: 3.731002
    epoch          : 206
    mel_loss       : 2.464120626449585
    fm_loss        : 0.8179916143417358
    gan_loss       : 3.4113640785217285
    loss           : 157.61148071289062
    discriminator loss: 3.731001615524292
    grad norm dis  : 18.76939582824707
    grad norm gen  : 1393.8935546875
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 207 [0/1 (0%)] G_Loss: 161.559204 D_Loss: 3.433256
    epoch          : 207
    mel_loss       : 2.589122772216797
    fm_loss        : 0.8790274262428284
    gan_loss       : 3.493600606918335
    loss           : 161.5592041015625
    discriminator loss: 3.433255672454834
    grad norm dis  : 18.465532302856445
    grad norm gen  : 876.252685546875
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Train Epoch: 208 [0/1 (0%)] G_Loss: 152.065063 D_Loss: 2.990364
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 208
    mel_loss       : 2.7549524307250977
    fm_loss        : 1.1707732677459717
    gan_loss       : 3.2659683227539062
    loss           : 152.0650634765625
    discriminator loss: 2.9903640747070312
    grad norm dis  : 16.976625442504883
    grad norm gen  : 1273.260009765625
Train Epoch: 209 [0/1 (0%)] G_Loss: 157.006393 D_Loss: 2.856700
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 209
    mel_loss       : 2.551464557647705
    fm_loss        : 1.103747010231018
    gan_loss       : 3.3832762241363525
    loss           : 157.0063934326172
    discriminator loss: 2.8566997051239014
    grad norm dis  : 23.250455856323242
    grad norm gen  : 1494.131591796875
Train Epoch: 210 [0/1 (0%)] G_Loss: 207.603119 D_Loss: 2.869040
    epoch          : 210
    mel_loss       : 2.590043306350708
    fm_loss        : 0.8618251085281372
    gan_loss       : 4.517542839050293
    loss           : 207.60311889648438
    discriminator loss: 2.869039535522461
    grad norm dis  : 22.72572898864746
    grad norm gen  : 3113.2626953125
Train Epoch: 211 [0/1 (0%)] G_Loss: 393.350677 D_Loss: 3.007843
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 211
    mel_loss       : 2.236682653427124
    fm_loss        : 0.539470374584198
    gan_loss       : 8.66744613647461
    loss           : 393.3506774902344
    discriminator loss: 3.007842540740967
    grad norm dis  : 12.221088409423828
    grad norm gen  : 7072.525390625
Train Epoch: 212 [0/1 (0%)] G_Loss: 148.376053 D_Loss: 3.225499
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 212
    mel_loss       : 2.161098003387451
    fm_loss        : 0.3134719729423523
    gan_loss       : 3.2352893352508545
    loss           : 148.3760528564453
    discriminator loss: 3.225498676300049
    grad norm dis  : 10.375391960144043
    grad norm gen  : 1082.5655517578125
Train Epoch: 213 [0/1 (0%)] G_Loss: 150.662369 D_Loss: 3.510020
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 213
    mel_loss       : 2.003556251525879
    fm_loss        : 0.4023992717266083
    gan_loss       : 3.285645008087158
    loss           : 150.66236877441406
    discriminator loss: 3.5100204944610596
    grad norm dis  : 14.618036270141602
    grad norm gen  : 1043.8551025390625
Train Epoch: 214 [0/1 (0%)] G_Loss: 133.961716 D_Loss: 3.664314
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
    epoch          : 214
    mel_loss       : 1.8238155841827393
    fm_loss        : 0.38170790672302246
    gan_loss       : 2.9194328784942627
    loss           : 133.9617156982422
    discriminator loss: 3.6643142700195312
    grad norm dis  : 16.750192642211914
    grad norm gen  : 1568.4388427734375
Train Epoch: 215 [0/1 (0%)] G_Loss: 138.629318 D_Loss: 3.883719
    epoch          : 215
    mel_loss       : 1.6658443212509155
    fm_loss        : 0.41903141140937805
    gan_loss       : 3.0250091552734375
    loss           : 138.6293182373047
    discriminator loss: 3.8837192058563232
    grad norm dis  : 27.955230712890625
    grad norm gen  : 1256.2838134765625
train:   0%|                                                                                                                      | 0/1 [00:00<?, ?it/s]
Traceback (most recent call last):                                                                                                | 0/1 [00:05<?, ?it/s]
Traceback (most recent call last):                                                                                                | 0/1 [00:05<?, ?it/s]
  File "/home/mac-mvak/code_disk/HiFi-GAN/train.py", line 113, in <module>
    main(config)
  File "/home/mac-mvak/code_disk/HiFi-GAN/train.py", line 77, in main
    trainer.train()
  File "/home/mac-mvak/code_disk/HiFi-GAN/hw_hifi/base/base_trainer.py", line 76, in train
    raise e
  File "/home/mac-mvak/code_disk/HiFi-GAN/hw_hifi/base/base_trainer.py", line 72, in train
    self._train_process()
  File "/home/mac-mvak/code_disk/HiFi-GAN/hw_hifi/base/base_trainer.py", line 84, in _train_process
    result = self._train_epoch(epoch)
  File "/home/mac-mvak/code_disk/HiFi-GAN/hw_hifi/trainer/trainer.py", line 107, in _train_epoch
    batch = self.process_batch(
  File "/home/mac-mvak/code_disk/HiFi-GAN/hw_hifi/trainer/trainer.py", line 182, in process_batch
    batch['loss'].backward()
  File "/home/mac-mvak/code_disk/HiFi-GAN/.venv/lib/python3.9/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/home/mac-mvak/code_disk/HiFi-GAN/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Saving checkpoint: saved/models/deepspeech/1201_040223/checkpoint-epoch216.pth ...